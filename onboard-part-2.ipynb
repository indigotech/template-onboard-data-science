{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8fff9273",
   "metadata": {},
   "source": [
    "# Onboarding DS - Part 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "906f26d9",
   "metadata": {},
   "source": [
    "Now that you have seen some of the most important packages we will use, let us introduce you to two of the main parts of a data science project: the exploratory data analysis and the data preparation.\n",
    "\n",
    "The exploratory data analysis is the step where you will know better your data: what your features are, how they are distributed, how they are related and what you can conclude by observing them in tables and graphs. Then, to effectively start using your data (in machine learning models and other functions), you must prepare it beforehand, with normalization techniques and missing data treatments, for example.\n",
    "\n",
    "In this notebook, we will use a mock project to show you some of the analysis and preparations we can do with data. You will do the coding on your own, but we will guide you through all the steps.\n",
    "\n",
    "\n",
    "<div class = 'alert alert-block alert-warning'> Feel free to reach anyone in the DS team whenever you have doubts or questions! Exchanging knowledge is one of the greatest and most meaningful values we have here :)\n",
    "</div>\n",
    "\n",
    "<div class = 'alert alert-block alert-success'> Along this notebook, there will be some green boxes like this one! They correspond to questions about SQL. They may seem random and unlinked to the main content of this notebook (indeed, they are a little bit out of context :P). However, they are related to a very useful knowledge that will be used afterwards in your real projects.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38c86801",
   "metadata": {},
   "source": [
    "## Packages\n",
    "\n",
    "Before we start, it is important to know that we are going to plot a lot of graphs along this notebook. To do so, there are many different Python packages you can use, such as Matplotlib and Seaborn. Here, we will use Plotly. We recommend you to install it using `pip3 install plotly`.\n",
    "\n",
    "Besides that, feel free to use this one or any other package when constructing your own analysis. Each one has its advantages and disadvantages. For instance, we chose to use Plotly due to its interactive plots and easy manipulation.\n",
    "\n",
    "Ok, let's start now:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38e72e47",
   "metadata": {},
   "source": [
    "<div class = 'alert alert-block alert-info'> Task 1: to observe and manipulate our data, we will use Plotly and the packages shown in the previous notebook: numpy and pandas. Import them as <b>np</b> and <b>pd</b> respectively.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03de538c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "from autocorrectors.exospart2 import part2exo2, part2exo4, part2exo10\n",
    "\n",
    "# TO DO\n",
    "# import the packages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91b209d0",
   "metadata": {},
   "source": [
    "We will work with a penguins **dataset** (Palmer Penguins dataset). It contains some physical characteristics of penguins from the Palmer Archipelago. There are penguins of different species in there and our goal is to group them accordingly to their species, based on their physical characteristics. This data is stored in a csv file, so we must import it into a Dataframe in order to use it. The `pd.read_csv` command imports the csv file into a dataframe (called `penguins` in this context). Then, `head()` shows us the first rows of the dataframe.\n",
    "\n",
    "Note: the original dataset is composed by 2 tables. Here we will start working with only one of them. However, feel free to use both ones and test your results :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bae9edac",
   "metadata": {},
   "outputs": [],
   "source": [
    "penguins = pd.read_csv('./data/penguins_dataset.csv')\n",
    "penguins.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e28d5a72",
   "metadata": {},
   "source": [
    "<div class = 'alert alert-block alert-info'> Task 2: We can see that our dataframe has a column \"Unnamed: 0\" that is useless for us. So delete the column \"Unnamed: 0\".<br>\n",
    "    \n",
    "Then, using the method <b>shape</b>, find out the number of rows and columns (n_rows and n_columns) in the penguins dataframe. Using <b>penguins.isnull().sum()</b> check if there are <b>null values</b> (in other words, missing values).<br><br>\n",
    "    \n",
    "Tip: look for <b>drop</b> in the pandas documentation\n",
    "</div>    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbc4db75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO\n",
    "# drop column \"Unnamed: 0\"\n",
    "\n",
    "n_rows = # find out the number of rows\n",
    "n_columns = # find out the number of columns\n",
    "\n",
    "# TO DO\n",
    "# check if there are missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a1fbd87",
   "metadata": {},
   "source": [
    "<div class = 'alert alert-block alert-success'> SQL Task: If we were manipulating the penguins data in SQL, how many results we would have after running the following query?<br>\n",
    "    <b>SELECT DISTINCT Island FROM penguins</b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28f95cfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_results = input(\"The number of instances in the result table is: \")\n",
    "part2exo2(n_rows, n_columns, nb_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b09c699d",
   "metadata": {},
   "source": [
    "An important thing you can do is checking which are the possible values of each column. Sometimes, there are values that you were not expecting and that can mess with your future analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a5f67e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(penguins['island'].unique())\n",
    "display(penguins['sex'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0472ea6a",
   "metadata": {},
   "source": [
    "Other than null values, the sex column contains weird data ('.') which we can treat as missing data too. There are many ways of treating missing data. One of them is deleting them (delete the row or the column, depending on how the null values are distributed in your dataset). It is usually useful when we have lots of data and we just want a general view of the context. Another possibility to deal with missing data is substituting it for reasonable values, by doing an interpolation, getting the mode, etc.\n",
    "\n",
    "<div class = 'alert alert-block alert-info'> Task 3: Replace the missing values with the mode value of the respective column.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0c796a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO\n",
    "# replace missing values with mode value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01328f51",
   "metadata": {},
   "source": [
    "## Data visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da52dd1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure(data=[go.Histogram(x = penguins['island'])])\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5be94f4",
   "metadata": {},
   "source": [
    "Through this histogram (\"graph of frequencies\"), we can observe that just a small part of the penguins live in Torgersen (around 15%) while almost half of all penguins are from Biscoe."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61636504",
   "metadata": {},
   "source": [
    "<div class = 'alert alert-block alert-success'> SQL Task: There are 2 tables, Islands and Roles, and to obtain the existing roles in each island, we took the Islands table and joined the Roles table, on the islands' names. Which kind of join (left/right/inner/full) did we use to get these result table?<br>\n",
    "    \n",
    "SQL query:<br>\n",
    "<b>SELECT DISTINCT role, island_name FROM Islands<br>\n",
    "___ JOIN Roles<br>\n",
    "    ON island_name = island;</b>\n",
    "</div>\n",
    "\n",
    "<img src=\"images/penguinstables.png\" alt=\"originals\" width=\"800\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68644146",
   "metadata": {},
   "outputs": [],
   "source": [
    "join_type = input(\"Which join was made? Type left, right, inner or full: \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9bd5fe7",
   "metadata": {},
   "source": [
    "<div class = 'alert alert-block alert-info'> Task 4: Using <b>make_subplots</b> from Plotly, plot histograms on the culmen length, culmen depth, flipper length, body mass and sex. Then calculate the mean value of the culmen length.\n",
    "    \n",
    "At last, observe what the method <b>describe()</b> does.\n",
    "\n",
    "Extra: plot a histogram showing the proportion of females and males on each island (tip: take a look on the histogram documentation on Plotly)\n",
    "</div>    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c1fadda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO\n",
    "# plot the histograms in subplots\n",
    "\n",
    "# TO DO\n",
    "# calculate the mean culmen length\n",
    "\n",
    "# TO DO\n",
    "# Extra: plot the histogram in which the islands are on x-axis,\n",
    "# and that shows the quantity of each sex on each island\n",
    "\n",
    "# TO DO\n",
    "# observe the following method \"describe\"\n",
    "penguins.describe()\n",
    "\n",
    "mean_culmen_length = input(\"Mean culmen length (give your answer with 2 decimal digits): \")\n",
    "part2exo4(mean_culmen_length, join_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1521d66e",
   "metadata": {},
   "source": [
    "<div class = 'alert alert-block alert-info'> Task 5: To better understand how data is statistically distributed, try to plot <b>box-plots</b>.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80e5f711",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO\n",
    "# plot box-plots"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdecd643",
   "metadata": {},
   "source": [
    "Do you notice something particular in the culmen depth and flipper length distributions? There are some points that do not follow the overall pattern: we call them **outliers**. They influence some metrics, affect normalization (check notebook 3) and may give a wrong perception of the big picture, that's why we must treat this peculiar data. They commonly represent poorly measured data or exceptions to the norm.\n",
    "\n",
    "What we usually do is take them out of our dataset. Since they represent a really small fraction of all data, deleting them will not affect our analysis. What is important to have in mind is how much data you will take out of your analysis: sometimes, many of the features have outliers, so you must be careful not to end up deleting a relevant portion of your observations; there must be a balance between what is acceptable to keep and what we can ignore.\n",
    "\n",
    "To remove the outliers, you can use statistical calculation or machine learning algorithms. Here, we will introduce you to [Isolation Forest](https://scikit-learn.org/stable/modules/outlier_detection.html#isolation-forest), useful to detect global outliers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a3cd51e",
   "metadata": {},
   "source": [
    "<div class = 'alert alert-block alert-info'> Task 6: Read about Isolation Forest and its hyperparameters, try to implement it and remove the outliers.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ff8077c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO\n",
    "# use Isolation Forest\n",
    "# (do not forget to import it)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d456b5a",
   "metadata": {},
   "source": [
    "There are many [different charts](https://plotly.com/python/basic-charts/) you can make to represent your data: scatter plots, bar and pie charts, etc. Depending on what you want to show, one fits better than other. Knowing when you can apply each of them is important, so let's practice a little bit.\n",
    "\n",
    "<div class = 'alert alert-block alert-info'> Task 7: We want to compare the mean body mass of the penguins from Biscoe, Dream and Torgersen and plot it. Which chart is better to represent this comparison among mean masses?<br>\n",
    "    \n",
    "Then, do a scatter plot in which each point is a penguin and the x and y axis are numerical features (from the penguins dataset) of your choice. \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75225542",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO\n",
    "# chart: mean body mass comparison\n",
    "\n",
    "# TO DO\n",
    "# scatter plot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a277439",
   "metadata": {},
   "source": [
    "Tables are also very important in data visualization. They help to summarize information and compare values.\n",
    "\n",
    "<div class = 'alert alert-block alert-info'> Task 8: Using the groupby pandas method, create a table with the mean values of each numeric feature with respect to the sex. In other words, calculate the average culmen length and depth, the average flipper length and the average body mass for the female penguins and for the male penguins.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c0faf99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO\n",
    "# create the table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29cf6ab0",
   "metadata": {},
   "source": [
    "<div class = 'alert alert-block alert-success'> SQL Task: How can we construct the same table in SQL? Choose an option:<br><br>\n",
    "    1) SELECT AVG(*) FROM penguins GROUP BY sex;<br>\n",
    "    2) SELECT sex, AVG(culmen_length_mm), AVG(culmen_depth_mm), AVG(flipper_length_mm), AVG(body_mass_g) GROUP BY sex FROM penguins;<br>\n",
    "    3) SELECT sex, AVG(culmen_length_mm), AVG(culmen_depth_mm), AVG(flipper_length_mm), AVG(body_mass_g) FROM penguins GROUP BY sex;<br>\n",
    "    4) SELECT AVG(*) GROUP BY sex FROM penguins;\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "487c4ec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_option = input(\"The right option is number: \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30a5e63c",
   "metadata": {},
   "source": [
    "An important analysis you can make is plotting the `correlation matrix`. It shows how correlated are the features among themselves. The values vary from -1 (inversely correlated) to 1 (strongly correlated). To plot the matrix as a heatmap, you may follow some steps:\n",
    "\n",
    "<div class = 'alert alert-block alert-info'> Task 9: Firstly, you may calculate the correlation between the features. You can use the pandas method <b>corr</b>. Then, you can choose between <b>imshow</b> from plotly.express and <b>Heatmap</b> from plotly.graph_objects to plot your matrix.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "631c3029",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO\n",
    "# create the correlation matrix using corr\n",
    "# then plot it as a heatmap\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09af2ace",
   "metadata": {},
   "source": [
    "The colors helps us to visualize which features are more correlated between them and which are not. The main diagonal of this matrix has all its values equal to 1 because it contains the correlation between a feature and this same feature. We can thus ignore this diagonal. It is important to observe that this matrix is symmetric as well.\n",
    "\n",
    "<div class = 'alert alert-block alert-info'> Task 10: Write down which feature has the highest correlation and which has the smallest correlation with the flipper length.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb4d736e",
   "metadata": {},
   "outputs": [],
   "source": [
    "hcorr = input(\"The feature with the highest correlation with flipper_length_mm is: \")\n",
    "lcorr = input(\"The feature with the lowest correlation with flipper_length_mm is: \")\n",
    "\n",
    "part2exo10(hcorr, lcorr, query_option)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cafbe37",
   "metadata": {},
   "source": [
    "This next cell will be helpful for us. We are going to continue our work in a new notebook dedicated to clustering. Therefore, in order to continue using the initially prepared data we already have, we will save it into a new file and import it in the next notebook.\n",
    "\n",
    "You can save the data into another csv file. However, there are many other options you can use and that may be more efficient. `parquet`, `pickle` and `feather` are examples of file formats you can use. Each one of them has its own unique characteristics (for instance, `parquet` works pretty well with partitioned tables) but they are all binary file formats to store dataframes. Therefore they have a considerably more compact memory size and you can store things and read from them faster than csv files."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d57d8ca9",
   "metadata": {},
   "source": [
    "<div class = 'alert alert-block alert-info'> Task 11: Choose one the the file formats (you can look for others as well) and save your updated penguins dataset.\n",
    "    \n",
    "Note: do not overwrite the original penguins dataset! Choose another name to your new file.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca966caa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO\n",
    "# save dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bebaa5a",
   "metadata": {},
   "source": [
    "<div class = 'alert alert-block alert-info'> Task 12: Add the new file in the .gitignore, commit your changes and push them to the remote repository.\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.7.3 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
