{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8fff9273",
   "metadata": {},
   "source": [
    "# Onboarding DS - Part 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "906f26d9",
   "metadata": {},
   "source": [
    "Now that you have seen some of the most important packages we will use, let us introduce you to the two of the main parts of a data science project: the exploratory data analysis and the data preparation.\n",
    "\n",
    "The exploratory data analysis is the step where you will know better your data: what your features are, how they are distributed, how they are related and what you can conclude observing them in tables and graphs. Then, to effectively start using your data (in machine learning models and other functions), you must prepare it beforehand, with normalization techniques and treating missing data, for example.\n",
    "\n",
    "In this notebook, we will show you some of the analysis and preparations we can do with the data through a mock project. You will do the coding on your own, but we will guide you through all the steps.\n",
    "\n",
    "<div class = 'alert alert-block alert-warning'> Feel free to reach anyone in the DS team whenever you have doubts or questions! Exchanging knowledge is one of the greatest and most meaningful values we have here :)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38c86801",
   "metadata": {},
   "source": [
    "## Packages\n",
    "\n",
    "Before we start, it is important to know that we are going to plot a lot of graphs along this notebook. To do so, there are many different Python packages you can use, such as Matplotlib and Seaborn. Here, we will use Plotly. We recommend you to install it using `pip3 install plotly`.\n",
    "\n",
    "Besides that, feel free to use this one or any other package when constructing your own analysis. Each one has its advantages and disadvantages. For instance, we chose to use Plotly due to its interactive plots and easy manipulation.\n",
    "\n",
    "Ok, let's start now:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38e72e47",
   "metadata": {},
   "source": [
    "<div class = 'alert alert-block alert-info'> Task 1: to observe and manipulate our data, we will use Plotly and the packages shown in the previous notebook: numpy and pandas. Import them as <b>np</b> and <b>pd</b> respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03de538c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "from autocorrectors.exospart2 import part2exo1, part2exo3, part2exo7\n",
    "\n",
    "# TO DO\n",
    "# import the packages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91b209d0",
   "metadata": {},
   "source": [
    "We will work with a penguins **dataset** (Palmer Penguins dataset). It contains some physical characteristics of penguins from the Palmer Archipelago. There are penguins of different species in there and our goal is to group them accordingly to their species, based on their physical characteristics. This data is stored in a csv file, so we must import it into a Dataframe in order to use it. The `pd.read_csv` command imports the csv file into a dataframe (called `penguins` in this context). Then, `head()` shows us the first rows of the dataframe.\n",
    "\n",
    "Note: the original dataset is composed by 2 tables. Here we will start working with only one of them. However, feel free to use both ones and test your results :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bae9edac",
   "metadata": {},
   "outputs": [],
   "source": [
    "penguins = pd.read_csv('./data/penguins_dataset.csv')\n",
    "penguins.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e28d5a72",
   "metadata": {},
   "source": [
    "<div class = 'alert alert-block alert-info'> Task 2: We can see that our dataframe has a column \"Unnamed: 0\" that is useless for us. So delete the column \"Unnamed: 0\".<br>\n",
    "    \n",
    "Then, using the method <b>shape</b>, find out the number of rows and columns (n_rows and n_columns) in the musics dataframe. Using <b>penguins.isnull().sum()</b> check if there are <b>null values</b> (in other words, missing values).<br><br>\n",
    "    \n",
    "Tip: look for <b>drop</b> in the pandas documentation\n",
    "</div>    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbc4db75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO\n",
    "# drop column \"Unnamed: 0\"\n",
    "\n",
    "n_rows = # find out the number of rows\n",
    "n_columns = # find out the number of columns\n",
    "\n",
    "# TO DO\n",
    "# check if there are missing values\n",
    "\n",
    "part2exo1(n_rows, n_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a51a6033",
   "metadata": {},
   "source": [
    "An important thing you can do is checking which are the possible values of each column. Sometimes, there are values that you were not expecting and that can mess with your future analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a5f67e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(penguins['island'].unique())\n",
    "display(penguins['sex'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0472ea6a",
   "metadata": {},
   "source": [
    "Other than null values, the sex column contains weird data ('.') which we can treat as missing data too. There are many ways of treating missing data. One of them is deleting them (delete the row or the column, depending on how the null values are distributed in your dataset). It is usually useful when we have lots of data and we just want a general view of the context. Another possibility to deal with missing data is substituting it for reasonable values, by doing an interpolation, getting the mode, etc.\n",
    "\n",
    "<div class = 'alert alert-block alert-info'> Task 3: Replace the missing values with the mode value of the respective column.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0c796a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO\n",
    "# replace missing values with mode value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01328f51",
   "metadata": {},
   "source": [
    "## Data visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da52dd1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure(data=[go.Histogram(x = penguins['island'])])\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5be94f4",
   "metadata": {},
   "source": [
    "Through this histogram (\"graph of frequencies\"), we can observe that just a small part of the penguins live in Torgersen (around 15%) while almost have of all penguins are from Biscoe."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9bd5fe7",
   "metadata": {},
   "source": [
    "<div class = 'alert alert-block alert-info'> Task 3: Using <b>make_subplots</b> from Plotly, plot histograms on the culmen length, culmen depth, flipper length, body mass and sex. Then calculate the mean lenght of a culmen length.\n",
    "    \n",
    "At last, observe what the method <b>describe()</b> does.\n",
    "\n",
    "Extra: plot a histogram showing the proportion of females and males on each island (tip: take a look on the histogram documentation on Plotly)\n",
    "</div>    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c1fadda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO\n",
    "# plot the histograms in subplots\n",
    "\n",
    "# TO DO\n",
    "# calculate the mean culmen length\n",
    "\n",
    "# TO DO\n",
    "# Extra: plot the histogram where the islands are on x-axis,\n",
    "# and showing the quantity of each sex on each island\n",
    "\n",
    "\n",
    "mean_culmen_length = float(input(\"Mean culmen length: \"))\n",
    "part2exo3(mean_culmen_length)\n",
    "\n",
    "penguins.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1521d66e",
   "metadata": {},
   "source": [
    "<div class = 'alert alert-block alert-info'> Task 4: To better understand how data is statistically distributed, try to plot <b>box-plots</b>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80e5f711",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO\n",
    "# plot box-plots"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a277439",
   "metadata": {},
   "source": [
    "Tables are also very important in data visualization. They help to summarize information and compare values.\n",
    "\n",
    "<div class = 'alert alert-block alert-info'> Task 5: Using the groupby pandas method, create a table with the mean values of each numeric feature with respect to the sex. In other words, calculate the average culmen length and depth, the average flipper length and the average body mass for the female penguins and for the male penguins."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe706570",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO\n",
    "# create the table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30a5e63c",
   "metadata": {},
   "source": [
    "An important analysis you can make if plotting the `correlation matrix`. It shows how correlated are the features among themselves. The values vary from -1 (inversely correlated) to 1 (strongly correlated). To plot the matrix as a heatmap, you may follow some steps:\n",
    "\n",
    "<div class = 'alert alert-block alert-info'> Task 6: Firstly, you may calculate the correlation between the features. You can use the pandas method <b>corr</b>. Then, you can choose between <b>imshow</b> from plotly.express and <b>Heatmap</b> from plotly.graph_objects to plot your matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "631c3029",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO\n",
    "# create the correlation matrix using corr\n",
    "# then plot it as a heatmap\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09af2ace",
   "metadata": {},
   "source": [
    "The colors helps us to visualize which features are more correlated between them and which are not. The main diagonal of this matrix has all its values equal to 1 because it contains the correlation between a feature and this same feature. We can thus ignore this diagonal. It is important to observe that this matrix is symmetric as well.\n",
    "\n",
    "<div class = 'alert alert-block alert-info'> Task 7: Write down which feature has the highest correlation and which has the smallest correlation with the flipper length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb4d736e",
   "metadata": {},
   "outputs": [],
   "source": [
    "hcorr = input(\"The feature with the highest correlation with flipper_length_mm is: \")\n",
    "lcorr = input(\"The feature with the lowest correlation with flipper_length_mm is: \")\n",
    "\n",
    "part2exo7(hcorr, lcorr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd72a7d6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
