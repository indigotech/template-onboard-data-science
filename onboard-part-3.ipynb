{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aab78d5f",
   "metadata": {},
   "source": [
    "# Onboarding DS - Part 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94bd65d6",
   "metadata": {},
   "source": [
    "Yay! We are already in the third part of this onboarding. Now, we will continue preparing the data and start clustering our penguins :D <br>\n",
    "Do not forget that you can always revisit the exploratory data analysis part and try other ways to prepare your data for clustering! None of the steps are immutable and it is an important part of the process to go back to previous analysis and reevaluate things (check out the [CRISP-DM](https://en.wikipedia.org/wiki/Cross-industry_standard_process_for_data_mining) methodology)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0fac881",
   "metadata": {},
   "source": [
    "## Packages and data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f059449",
   "metadata": {},
   "source": [
    "Here, we will use the same packages we were using before and add a new one: sci-kit learn (sklearn). This package is really helpful when we want to build machine learning models. Install it the same way you installed the other packages earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41d54257",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.mixture import GaussianMixture"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b135807a",
   "metadata": {},
   "source": [
    "Let's import our penguins dataset (the one we created at the end of the second notebook) and continue working with it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "417bed73",
   "metadata": {},
   "outputs": [],
   "source": [
    "penguins = # TO DO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09877254",
   "metadata": {},
   "source": [
    "## Data prep (continuation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e617f7f",
   "metadata": {},
   "source": [
    "Do you remember the histograms we did previously? One thing that is important to notice is the range of values of each feature: the body mass varies from 2700 up to 6300 grams, while the culmen depth can have values between 13 and 21.5 mm. In other words, the scale of the features are not the same.\n",
    "\n",
    "It can be a problem when we want to use clustering models because, in general, these models are based on the idea of comparing distances between data points and when we have different value ranges, a feature may unintentionally gain more relevance over another one. That is why we should normalize the data! There are many different techniques to do so, and depending on your intentions, you may prefer one over another. In some cases, you are more interested in putting all features in a same range of values; in other cases, you want your data to follow a normal distribution or you just want to deal with smaller values (like the square root of the original ones). We invite you to take a deeper look in this topic ([you can start here :) ](https://scikit-learn.org/stable/modules/preprocessing.html))!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd3298ec",
   "metadata": {},
   "source": [
    "<div class = 'alert alert-block alert-info'> Task 1: Choose one of the normalization techniques and rescale your features. Save this rescaled values in a new dataframe penguins_sc.<br>\n",
    "    \n",
    "Tip: if you choose to use one of the sklearn functions to rescale your data, do not forget to import it!<br>\n",
    "    \n",
    "Tip2: notice that removing outliers is important; otherwise your rescaling would be affected by the really high/low values that do not meet the rest of you data.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abe252e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO\n",
    "# normalize data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44955017",
   "metadata": {},
   "source": [
    "Since we cannot plot string values in a graph, we must treat the `island` and `sex` columns. We can use Label Encoding, to transforms string categories into numerical ones, but this only works when there is some kind of ordering in the categories. Another solution is doing the One Hot Encoding: it transforms each of the category values into a boolean column and sets `1` if the concerning value matches to the row's actual category, `0` otherwise.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "571cd533",
   "metadata": {},
   "source": [
    "<div class = 'alert alert-block alert-info'> Task 2: Since there is no way of ordering the islands or the sex, let's use the One Hot Encoding approach and turn this features into boolean ones.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b24ec1fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO\n",
    "# create an instance of One Hot Encoder for the sex attribute and another for the island attribute\n",
    "# and apply it on the features\n",
    "#\n",
    "# you can drop redundant and useless features at this point"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad1cfc3d",
   "metadata": {},
   "source": [
    "## Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a916f33b",
   "metadata": {},
   "source": [
    "We are finally getting to the clustering part!\n",
    "\n",
    "Clustering is one of the of the applications of unsupervised learning: when you do not have labels and your model may find patterns and ways to group the data by itself. K-Means, GMM (Gaussian Mixture Models) and DBSCAN are examples of clustering algorithms. We invite you to know [read more](https://scikit-learn.org/stable/modules/clustering.html#clustering) about them and find out other ones that exist and to try applying them in this onboarding.\n",
    "\n",
    "We will guide you through implementing GMM."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55158d52",
   "metadata": {},
   "source": [
    "For both K-Means and GMM, you need to give the number of clusters you want as input. To find out which number is the best, there are some metrics we can calculate and therefore make our choice. When we are working with K-Means, we normally use the Silhouette score and inertia. For GMM, BIC and AIC are more used. We calculate those metrics for each number of clusters we are thinking about using, then we pick the number that showed the best results.\n",
    "\n",
    "For BIC and AIC, the lower the score, the better. We invite you to find out how they are calculated.\n",
    "[GMM from sklearn](https://scikit-learn.org/stable/modules/generated/sklearn.mixture.GaussianMixture.html#sklearn.mixture.GaussianMixture) already has in-built aic and bic methods (check on the documentation), so we only need to store these values and compare them afterwards."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f129b6ed",
   "metadata": {},
   "source": [
    "### GMM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91c8d489",
   "metadata": {},
   "source": [
    "The idea of this algorithm is to group similar instances in a same cluster, according to their features (in this case, our clusters represent the distinct penguin species). It works in an iterative way, so the algorithm stops when its output converges (the actual output is equal or very close to the previous one). In the input, you must specify the dataset you are working with, in how many clusters you want to split your data, the covariance type (regarding the covariance matrix and the degrees of freedom in the clusters' shape), some convergence hyperparameters and other values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4d6beb4",
   "metadata": {},
   "source": [
    "<div class = 'alert alert-block alert-info'> Task 3: First of all, choose which features from the penguins dataset you will take into consideration during the clustering (you can pick all of them if you wish) and create a new dataframe <b>data</b> with these features.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5803783",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = # TO DO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4278255",
   "metadata": {},
   "source": [
    "<div class = 'alert alert-block alert-info'> Task 4: Adapt the function below to test the range of number of clusters you wish. Look up the GMM documentation on sci-kit learn and find out what the <b>covariance type</b> hyperparameter is. Try changing it, from full to tied, diagonal and spherical and run the aic_bic function again (to facilitate visualization, adapt the function so you can plot all different covariance types simultaneouly).\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aecb1a20",
   "metadata": {},
   "outputs": [],
   "source": [
    "def aic_bic(data):\n",
    "    aics = []\n",
    "    bics = []\n",
    "    \n",
    "    for i in range(2,15):\n",
    "        gmm = GaussianMixture(n_components=i, covariance_type='full', random_state=0)\n",
    "        y = gmm.fit_predict(data)\n",
    "        aics.append(gmm.aic(data))\n",
    "        bics.append(gmm.bic(data))\n",
    "  \n",
    "    fig = make_subplots(rows=2, cols=1)\n",
    "\n",
    "    fig.append_trace(go.Scatter(\n",
    "        x=[i for i in range(2,15)],\n",
    "        y=aics,\n",
    "        name='AIC'\n",
    "    ), row=1, col=1)\n",
    "\n",
    "    fig.append_trace(go.Scatter(\n",
    "        x=[i for i in range(2,15)],\n",
    "        y=bics,\n",
    "        name='BIC'\n",
    "    ), row=2, col=1)\n",
    "\n",
    "    fig.update_layout(height=600, width=600, title_text=\"Choosing number of clusters\")\n",
    "    fig.show()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eac5b86",
   "metadata": {},
   "outputs": [],
   "source": [
    "aic_bic(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59f7815c",
   "metadata": {},
   "source": [
    "<div class = 'alert alert-block alert-info'> Task 5: Now, run the GMM with the best hyperparameters you found and plot your results in a 3D scatter plot. Do not hesitate to try GMM with other n_components values. Sometimes, it will be more convenient for you to work with a lower or higher number of clusters, even if it is different from the ideal one according to the graphs above.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62d37ae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO\n",
    "# GMM with chosen hyperparameters\n",
    "\n",
    "# TO DO\n",
    "# 3D scatter plot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c805016",
   "metadata": {},
   "source": [
    "## Analyzing our clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bcdb90d",
   "metadata": {},
   "source": [
    "Now that you have chosen the hyperparameters of the clustering and that you have applied the GMM to our dataset, we can analyze each of the groups deeply. Through this study, we can identify **who** makes part of the cluster."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfd6e77e",
   "metadata": {},
   "source": [
    "<div class = 'alert alert-block alert-info'> Task 6: Do you remember the charts we plotted in the previous notebook? Now, try to plot some of them again comparing the properties/characteristics of each cluster. For instance: plot box-plots comparing the distribution of culmen depth and body mass values of the penguins from each cluster.<br>\n",
    "    \n",
    "Extra: one interesting chart you may try is a bubble chart: it is a scatter plot, but the size of the points on it is proportional to the size of the data they represent. We usually use it to compare the clusters (not the instances themselves). Choose 2 numerical features from the penguins dataset and plot a 2D bubble chart.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44d106b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO\n",
    "# box-plots\n",
    "\n",
    "# TO DO\n",
    "# bubble chart"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72c8a5b7",
   "metadata": {},
   "source": [
    "<div class = 'alert alert-block alert-info'> Task 7: What can you conclude about the penguins? Try to describe the penguins from each species you have found (which species is heavier, which has the longer culmen, etc.).\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
